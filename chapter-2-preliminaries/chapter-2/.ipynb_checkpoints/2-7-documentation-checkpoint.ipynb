{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e22e8d8-4226-4987-9bbf-df3b1b7d4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60caa158-fc45-4bf0-a833-9cd52574776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']\n"
     ]
    }
   ],
   "source": [
    "# We can use the dir function to learn what classes and functions can be called from a module\n",
    "\n",
    "print(dir(torch.tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149552a4-0ecd-4436-b5b9-a3d020357b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'CumulativeDistributionTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PositiveDefiniteTransform', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'SoftplusTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', 'Wishart', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart']\n"
     ]
    }
   ],
   "source": [
    "print(dir(torch.distributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ef20b4-a7ae-4c7c-8481-b605201b2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can typucally avoid variables prefexed or bookended with _, which are private/special\n",
    "# may hazard a guess that torch.distributions gives a range of probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a25cb2e-e0f7-4720-8dbd-d94bb03e9d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function ones in module torch:\n",
      "\n",
      "ones(...)\n",
      "    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "    \n",
      "    Returns a tensor filled with the scalar value `1`, with the shape defined\n",
      "    by the variable argument :attr:`size`.\n",
      "    \n",
      "    Args:\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "            Can be a variable number of arguments or a collection like a list or tuple.\n",
      "    \n",
      "    Keyword arguments:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.ones(2, 3)\n",
      "        tensor([[ 1.,  1.,  1.],\n",
      "                [ 1.,  1.,  1.]])\n",
      "    \n",
      "        >>> torch.ones(5)\n",
      "        tensor([ 1.,  1.,  1.,  1.,  1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also use the help function to get specific help on functions\n",
    "\n",
    "help(torch.ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "750a3d15-4ff3-43b2-9462-0655cf3d553f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
       "\n",
       "Returns a tensor filled with the scalar value `1`, with the shape defined\n",
       "by the variable argument :attr:`size`.\n",
       "\n",
       "Args:\n",
       "    size (int...): a sequence of integers defining the shape of the output tensor.\n",
       "        Can be a variable number of arguments or a collection like a list or tuple.\n",
       "\n",
       "Keyword arguments:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
       "        Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
       "    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
       "        Default: ``torch.strided``.\n",
       "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
       "        Default: if ``None``, uses the current device for the default tensor type\n",
       "        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
       "        for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
       "    requires_grad (bool, optional): If autograd should record operations on the\n",
       "        returned tensor. Default: ``False``.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.ones(2, 3)\n",
       "    tensor([[ 1.,  1.,  1.],\n",
       "            [ 1.,  1.,  1.]])\n",
       "\n",
       "    >>> torch.ones(5)\n",
       "    tensor([ 1.,  1.,  1.,  1.,  1.])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Equivalently\n",
    "torch.ones??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5039359f-f841-432e-b7fc-d3037197d835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
