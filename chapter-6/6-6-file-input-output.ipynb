{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3506f776-9474-48d0-8bce-2d494f7e8692",
   "metadata": {},
   "source": [
    "# File I/O\n",
    "\n",
    "What about if we want to save and load models on disk! Furthermore, training process may take days and it is worth checkpoointing this training at intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc63d181-4dcb-4226-b02c-32936bf402c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e05222-1c1f-4e66-af7c-d89ac60e7350",
   "metadata": {},
   "source": [
    "### For invidivual tensors, we can save and load these using the built-in .save() and .load() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e0f49a-e1ae-4528-ab5a-ab1682d01f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6218cd8-f83b-4906-9733-45095275abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.load('x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4bbc01-e857-4d1a-9ab1-a959996a611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a1530-e5c0-426b-aff9-043852478ade",
   "metadata": {},
   "source": [
    "###  We can also save a list of tensors and load them back into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbe9d3f7-f703-49f5-bdf0-5f8c16b0b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y], 'x-files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fcfad27-7d21-4103-9a9a-21f6ba7b128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, y2 = torch.load('x-files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912c3f0a-eff3-465e-abbe-73cda625c7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247286f-e4f8-4e64-a857-f6b080ec7614",
   "metadata": {},
   "source": [
    "###Â We can even read and write dictionaries which map from strings to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66f8c98d-8fb1-4a83-921b-007506b43fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]), 'x', 'y'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x', x, 'y', y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923644e5-30c7-4c48-8639-c37fe5d8b3da",
   "metadata": {},
   "source": [
    "## Loading and Saving Model Parameters\n",
    "\n",
    "Of course, while loading and saving individual tensors is very useful, loading and saving entire models this way would be much more tedious. PyTorch offers the flexibility to save and load entire networks. Note, that this will only be saving the _parameters_ of these networks, not the entire model. Models may contain arbitrary code, so we will have to write separate code to specify the model and load the parameters in fromd disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "451e6e6b-733a-417c-afd3-052b35f93904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickrowe/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.output = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa2d90-2de2-4e9d-ad94-a2a4b46848bf",
   "metadata": {},
   "source": [
    "We can access the current state of our MLP with state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acd1d95f-5c98-4538-b2ac-e16fb5d73d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[-0.0749,  0.1870,  0.2081,  ..., -0.1018,  0.0288, -0.1384],\n",
       "                      [ 0.0284, -0.0653,  0.0959,  ..., -0.0086,  0.2058, -0.1934],\n",
       "                      [ 0.1021,  0.1825,  0.0777,  ...,  0.1903,  0.0897, -0.0154],\n",
       "                      ...,\n",
       "                      [-0.1280, -0.2099, -0.0647,  ..., -0.1688,  0.1736,  0.2047],\n",
       "                      [-0.0763,  0.0649, -0.1289,  ..., -0.1129,  0.0253,  0.2184],\n",
       "                      [-0.0741, -0.1477, -0.1806,  ..., -0.1244, -0.0063, -0.1170]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([ 0.0843, -0.1556, -0.1968, -0.0914,  0.0962,  0.0352, -0.0317, -0.1255,\n",
       "                      -0.1528, -0.1287, -0.1293, -0.1812,  0.0312,  0.0436,  0.0065,  0.1241,\n",
       "                       0.0789,  0.0033,  0.0422,  0.0144,  0.2108,  0.1877,  0.0428, -0.1436,\n",
       "                      -0.1105, -0.0628,  0.1512, -0.1089, -0.1569, -0.0309,  0.1342, -0.1205,\n",
       "                       0.1990, -0.1666,  0.1499, -0.0990,  0.1480,  0.0484, -0.1071,  0.2168,\n",
       "                       0.0054, -0.0886,  0.0156, -0.1513, -0.0113,  0.0431,  0.1460,  0.1379,\n",
       "                      -0.0482,  0.0065, -0.0420, -0.1652,  0.1032, -0.0050,  0.0826, -0.1409,\n",
       "                       0.1835, -0.0342, -0.0102, -0.1097,  0.0843,  0.2076, -0.1134,  0.0163,\n",
       "                       0.1836,  0.2130, -0.0772, -0.0730, -0.1613, -0.0767,  0.1064,  0.0488,\n",
       "                      -0.1023,  0.2124,  0.0935, -0.1950, -0.1663,  0.2232,  0.1147, -0.0087,\n",
       "                      -0.0449,  0.0632, -0.0702, -0.2023, -0.0352,  0.0187,  0.0108,  0.1376,\n",
       "                      -0.1569,  0.2204,  0.1783, -0.1310,  0.1441, -0.0881, -0.0465,  0.0030,\n",
       "                      -0.1044, -0.1224, -0.0973,  0.1985,  0.1543,  0.0707,  0.0347, -0.0373,\n",
       "                      -0.0457, -0.0726, -0.1007, -0.0570, -0.1390,  0.0867,  0.1263,  0.1751,\n",
       "                       0.1993,  0.2083,  0.1336, -0.2169, -0.1761,  0.0634, -0.0052,  0.1062,\n",
       "                      -0.1613,  0.1412, -0.0435,  0.0456, -0.2157, -0.1821,  0.1340,  0.0791,\n",
       "                       0.2234,  0.0327,  0.0819, -0.0534, -0.2160, -0.0454,  0.1635, -0.0287,\n",
       "                      -0.0040,  0.0901,  0.0868,  0.0423,  0.1659, -0.2031,  0.1187, -0.0193,\n",
       "                      -0.0060,  0.0210,  0.0788, -0.1481,  0.0703, -0.0118, -0.1263, -0.0182,\n",
       "                      -0.0281,  0.1340,  0.0714,  0.1618, -0.0086, -0.1202, -0.1839,  0.0051,\n",
       "                      -0.0745,  0.1961, -0.0278, -0.0579, -0.1117,  0.1467, -0.0553,  0.0716,\n",
       "                      -0.0758, -0.1763, -0.1710,  0.0854,  0.2196, -0.2090, -0.2032,  0.0736,\n",
       "                       0.1396,  0.1931, -0.2126,  0.2210,  0.1634, -0.0219,  0.0635,  0.2000,\n",
       "                       0.1130,  0.1514, -0.1866, -0.1570,  0.0421,  0.1585, -0.1000, -0.2039,\n",
       "                       0.0373, -0.1984, -0.0445,  0.0523,  0.1429, -0.0018,  0.1760,  0.0645,\n",
       "                       0.1936, -0.2190, -0.2115, -0.1361, -0.0671,  0.1828, -0.2117,  0.0561,\n",
       "                       0.0281,  0.0486, -0.0045, -0.0377,  0.0273,  0.1336, -0.0414,  0.1894,\n",
       "                      -0.1925,  0.1213,  0.1930,  0.1639, -0.0270,  0.2197,  0.0162,  0.1306,\n",
       "                       0.1677, -0.1529, -0.1168,  0.1003,  0.1441, -0.0165, -0.0117, -0.1840,\n",
       "                      -0.0127, -0.1148,  0.0100, -0.2210,  0.1831, -0.0074, -0.1365, -0.1457,\n",
       "                      -0.0529,  0.2235,  0.0655, -0.0887, -0.0195, -0.0678,  0.2233,  0.1529,\n",
       "                      -0.1913, -0.2093, -0.2013, -0.2083, -0.0841,  0.0006, -0.1433, -0.0588])),\n",
       "             ('output.weight',\n",
       "              tensor([[ 0.0609, -0.0088,  0.0455,  ...,  0.0287, -0.0574,  0.0118],\n",
       "                      [-0.0563, -0.0071,  0.0031,  ...,  0.0294, -0.0202,  0.0350],\n",
       "                      [ 0.0619,  0.0049, -0.0145,  ...,  0.0398, -0.0409, -0.0537],\n",
       "                      ...,\n",
       "                      [-0.0114, -0.0524, -0.0602,  ..., -0.0144,  0.0145, -0.0107],\n",
       "                      [ 0.0429,  0.0542, -0.0187,  ..., -0.0506,  0.0295,  0.0422],\n",
       "                      [-0.0489, -0.0156,  0.0107,  ..., -0.0615,  0.0106, -0.0390]])),\n",
       "             ('output.bias',\n",
       "              tensor([ 0.0275,  0.0526, -0.0210,  0.0026, -0.0008, -0.0034, -0.0036, -0.0092,\n",
       "                       0.0251, -0.0105]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f33971-2182-41de-943c-6ca15b2eb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can write this state dict to disk with torch.save\n",
    "\n",
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62e54b-7caa-478a-93f3-18a346971de2",
   "metadata": {},
   "source": [
    "To recover the model using this state dict, we instantiate a clone of the model, but rather than initializing the parameters randomly, we read in the parameters stored in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72c3e354-e402-4d95-8428-61a37da98c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edbade0e-5ffa-42d9-b57e-4921871d6a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify that we have, in fact, loaded the correct model...\n",
    "\n",
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c78fd9-2c42-4e91-a774-da46f17b16c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
