{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1dbbd7-4f88-41b6-9608-072789854480",
   "metadata": {},
   "source": [
    "# Parameter Management\n",
    "\n",
    "When we have trained a modle, we may need access to the parameters in order to make future predictions, save our model to disk, or for examination for debugging or gaining scientific insight. \n",
    "\n",
    "Often, we can leave these details to the deep learning frameworks, but sometimes we will need to deal with them directly. In this notebook we will look at \n",
    "1. Accessing parameters for debugging, diagnostics and visualisation\n",
    "2. sharing parameters across different model components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1bac38-635f-4f01-a305-2cc9597165f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0b3aef-9af3-4e35-9a86-f4d3ab5ac84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickrowe/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.LazyLinear(8),\n",
    "    nn.ReLU(),\n",
    "    nn.LazyLinear(1)\n",
    ")\n",
    "\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3afc04-ea12-4c85-93d9-3993ddb48db3",
   "metadata": {},
   "source": [
    "## Parameter Access\n",
    "\n",
    "When a model is defined via the `Sequential` class, we can access any individual layer by indexing into it as though it were a list. Each layers parameters are conveniently located in its attributes.\n",
    "\n",
    "For the net defined below, we can see that the model is composed of a tensor of weights, and a single bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01eb58f-413c-4ebb-9194-58e086bfd57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0765,  0.3355, -0.1366,  0.1230, -0.2265, -0.0055, -0.1866, -0.1136]])),\n",
       "             ('bias', tensor([0.2870]))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78e6e1-9b08-4292-9256-5f5e1a8f2a05",
   "metadata": {},
   "source": [
    "### Accessing Individual Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd66eb63-9fbc-4154-97fc-a32b37e6852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.2870], requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "\n",
      "tensor([0.2870])\n"
     ]
    }
   ],
   "source": [
    "# We can access the individual parameters via the parameter class\n",
    "# The parameter is a complex object containing all sorts of metadata, so the value must be requested explicitly.\n",
    "\n",
    "print(net[2].bias)\n",
    "print(type(net[2].bias))\n",
    "print()\n",
    "print(net[2].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebcf58b3-5c4b-4106-bfc6-72e6b6af08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# We can also access the gradient, though this does not exist yet for this parameter\n",
    "print(net[2].bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df42bce-5542-4e66-adeb-ebf4ece360cb",
   "metadata": {},
   "source": [
    "### All parameters at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d150c72b-b340-4727-8368-bf884cc56727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight', torch.Size([8, 4])),\n",
       " ('0.bias', torch.Size([8])),\n",
       " ('2.weight', torch.Size([1, 8])),\n",
       " ('2.bias', torch.Size([1]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43931466-9714-476e-8e6d-4b4137e78f34",
   "metadata": {},
   "source": [
    "## Tied Parameters\n",
    "\n",
    "Often, we may wish to share parameters across multiple layers...\n",
    "\n",
    "In this example, we ensure not just that the values are the same, but that the tensor is literally the same obvject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c271e582-507d-4460-8afa-d9fd701da2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "shared = nn.LazyLinear(8)\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.LazyLinear(1))\n",
    "net(X)\n",
    "\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# Make sure that they are actually the same object rather than just having the\n",
    "# same value\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5ed26-4fe1-4bd8-a5f9-1830197ae064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
